[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "LabelEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "load_and_explore_data",
        "kind": 2,
        "importPath": "data_clensing.titanic_survival_model",
        "description": "data_clensing.titanic_survival_model",
        "peekOfCode": "def load_and_explore_data(file_path):\n    \"\"\"Load the dataset and perform initial exploration\"\"\"\n    print(\"Loading Titanic dataset...\")\n    df = pd.read_csv(file_path)\n    print(f\"Dataset shape: {df.shape}\")\n    print(\"\\nColumn information:\")\n    print(df.info())\n    print(\"\\nFirst few rows:\")\n    print(df.head())\n    print(\"\\nSurvival rate:\")",
        "detail": "data_clensing.titanic_survival_model",
        "documentation": {}
    },
    {
        "label": "preprocess_data",
        "kind": 2,
        "importPath": "data_clensing.titanic_survival_model",
        "description": "data_clensing.titanic_survival_model",
        "peekOfCode": "def preprocess_data(df):\n    \"\"\"Clean and preprocess the data for modeling\"\"\"\n    # Create a copy to avoid modifying original data\n    data = df.copy()\n    # Feature engineering\n    # Extract title from name\n    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n                                          'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    data['Title'] = data['Title'].replace('Mlle', 'Miss')",
        "detail": "data_clensing.titanic_survival_model",
        "documentation": {}
    },
    {
        "label": "train_models",
        "kind": 2,
        "importPath": "data_clensing.titanic_survival_model",
        "description": "data_clensing.titanic_survival_model",
        "peekOfCode": "def train_models(X, y):\n    \"\"\"Train multiple models and compare their performance\"\"\"\n    # Split the data\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n    # Scale features for logistic regression\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    # Initialize models\n    models = {",
        "detail": "data_clensing.titanic_survival_model",
        "documentation": {}
    },
    {
        "label": "analyze_feature_importance",
        "kind": 2,
        "importPath": "data_clensing.titanic_survival_model",
        "description": "data_clensing.titanic_survival_model",
        "peekOfCode": "def analyze_feature_importance(model, feature_names):\n    \"\"\"Analyze and plot feature importance for tree-based models\"\"\"\n    if hasattr(model, 'feature_importances_'):\n        importance_df = pd.DataFrame({\n            'feature': feature_names,\n            'importance': model.feature_importances_\n        }).sort_values('importance', ascending=False)\n        print(\"\\nFeature Importance:\")\n        print(importance_df)\n        # Plot feature importance",
        "detail": "data_clensing.titanic_survival_model",
        "documentation": {}
    },
    {
        "label": "predict_survival",
        "kind": 2,
        "importPath": "data_clensing.titanic_survival_model",
        "description": "data_clensing.titanic_survival_model",
        "peekOfCode": "def predict_survival(model, scaler, label_encoders, passenger_data, model_name):\n    \"\"\"Make prediction for a new passenger\"\"\"\n    # Create a dataframe with the passenger data\n    passenger_df = pd.DataFrame([passenger_data])\n    # Apply same preprocessing\n    for feature, le in label_encoders.items():\n        if feature in passenger_df.columns:\n            # Handle unknown categories\n            try:\n                passenger_df[feature] = le.transform(passenger_df[feature])",
        "detail": "data_clensing.titanic_survival_model",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "data_clensing.titanic_survival_model",
        "description": "data_clensing.titanic_survival_model",
        "peekOfCode": "def main():\n    \"\"\"Main function to run the complete analysis\"\"\"\n    # Load and explore data\n    df = load_and_explore_data('category_text.csv')\n    # Preprocess data\n    X, y, label_encoders, processed_data = preprocess_data(df)\n    print(f\"\\nFeatures used for modeling: {list(X.columns)}\")\n    print(f\"Feature matrix shape: {X.shape}\")\n    # Train models\n    results, X_test, y_test, scaler = train_models(X, y)",
        "detail": "data_clensing.titanic_survival_model",
        "documentation": {}
    }
]